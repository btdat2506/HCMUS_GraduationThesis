@article{chipyard,
  author  = {Amid, Alon and Biancolin, David and Gonzalez, Abraham and Grubb, Daniel and Karandikar, Sagar and Liew, Harrison and Magyar,   Albert and Mao, Howard and Ou, Albert and Pemberton, Nathan and Rigge, Paul and Schmidt, Colin and Wright, John and Zhao, Jerry and Shao, Yakun Sophia and Asanovi\'{c}, Krste and Nikoli\'{c}, Borivoje},
  journal = {IEEE Micro},
  title   = {Chipyard: Integrated Design, Simulation, and Implementation Framework for Custom SoCs},
  year    = {2020},
  volume  = {40},
  number  = {4},
  pages   = {10-21},
  doi     = {10.1109/MM.2020.2996616},
  issn    = {1937-4143}
}

@inbook{gemini-dac,
  author    = {Genc, Hasan and Kim, Seah and Amid, Alon and Haj-Ali, Ameer and Iyer, Vighnesh and Prakash, Pranav and Zhao, Jerry and Grubb, Daniel and Liew, Harrison and Mao, Howard and Ou, Albert and Schmidt, Colin and Steffl, Samuel and Wright, John and Stoica, Ion and Ragan-Kelley, Jonathan and Asanovic, Krste and Nikolic, Borivoje and Shao, Yakun Sophia},
  title     = {Gemmini: Enabling Systematic Deep-Learning Architecture Evaluation via Full-Stack Integration},
  year      = {2022},
  isbn      = {9781665432740},
  publisher = {IEEE Press},
  url       = {https://doi.org/10.1109/DAC18074.2021.9586216},
  abstract  = {DNN accelerators are often developed and evaluated in isolation without considering the cross-stack, system-level effects in real-world environments. This makes it difficult to appreciate the impact of System-on-Chip (SoC) resource contention, OS overheads, and programming-stack inefficiencies on overall performance/energy-efficiency. To address this challenge, we present Gemmini, an open-source1, full-stack DNN accelerator generator. Gemmini generates a wide design-space of efficient ASIC accelerators from a flexible architectural template, together with flexible programming stacks and full SoCs with shared resources that capture system-level effects. Gemmini-generated accelerators have also been fabricated, delivering up to three orders-of-magnitude speedups over high-performance CPUs on various DNN benchmarks.},
  booktitle = {Proceedings of the 58th Annual ACM/IEEE Design Automation Conference},
  pages     = {769–774},
  numpages  = {6}
}

@techreport{asanovic2016rocketchip,
  title       = {{The Rocket Chip Generator}},
  author      = {Asanovi{\'c}, Krste and Avi{\v{z}}ienis, Rimas and Bachrach, Jonathan and Beamer, Scott and Biancolin, David and Celio, Christopher and Cook, Henry and Dabbelt, Palmer and Hauser, John and Izraelevitz, Adam and Karandikar, Sagar and Keller, Benjamin and Kim, Donggyu and Koenig, John and Lee, Yunsup and Love, Eric and Maas, Martin and Magyar, Albert and Mao, Howard and Moreto, Miquel and Ou, Albert and Patterson, David and Richards, Brian and Schmidt, Colin and Twigg, Stephen and Vo, Huy and Waterman, Andrew},
  year        = {2016},
  institution = {Electrical Engineering and Computer Sciences, University of California, Berkeley},
  number      = {UCB/EECS-2016-17},
  url         = {http://www.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-17.html}
}

@article{celio2018broom,
  author   = {Celio, Christopher and Chiu, Pi-Feng and Asanović, Krste and Nikolić, Borivoje and Patterson, David},
  journal  = {IEEE Micro},
  title    = {BROOM: An Open-Source Out-of-Order Processor With Resilient Low-Voltage Operation in 28-nm CMOS},
  year     = {2019},
  volume   = {39},
  number   = {2},
  pages    = {52-60},
  keywords = {Open source software;Random access memory;Design methodology;CMOS process;Generators;Voltage control;Agile software development},
  doi      = {10.1109/MM.2019.2897782}
}


@inproceedings{zhao2020sonicboom_ieee,
  title     = {{SonicBOOM: The 3rd Generation Berkeley Out-of-Order Machine}},
  author    = {Zhao, Jerry and Gonzalez, Abraham and Korpan, Ben and Asanovic, Krste},
  booktitle = {2020 Workshop on Computer Architecture Research with RISC-V (CARRV)},
  year      = {2020},
  doi       = {10.1109/CARRV51705.2020.9408173},
  publisher = {IEEE}
}



@inproceedings{6241660,
  author    = {Bachrach, Jonathan and Vo, Huy and Richards, Brian and Lee, Yunsup and Waterman, Andrew and Avižienis, Rimas and Wawrzynek, John and Asanović, Krste},
  booktitle = {DAC Design Automation Conference 2012},
  title     = {Chisel: Constructing hardware in a Scala embedded language},
  year      = {2012},
  volume    = {},
  number    = {},
  pages     = {1212-1221},
  keywords  = {Hardware;Hardware design languages;Generators;Registers;Wires;Vectors;Finite impulse response filter;CAD},
  doi       = {10.1145/2228360.2228584}
}

@inproceedings{bachrach2012chisel,
  title     = {{Chisel: Constructing Hardware in a Scala Embedded Language}},
  author    = {Bachrach, Jonathan and Asher, Huu and Jevnikar, Jonathan and Nikolic, Borivoje and Patterson, David and Asanovic, Krste},
  booktitle = {Proceedings of the 49th Annual Design Automation Conference (DAC)},
  pages     = {645-654},
  year      = {2012},
  doi       = {10.1145/2228362.2228479},
  publisher = {ACM}
}

@inproceedings{10.1145/2228360.2228584,
  author    = {Bachrach, Jonathan and Vo, Huy and Richards, Brian and Lee, Yunsup and Waterman, Andrew and Avi\v{z}ienis, Rimas and Wawrzynek, John and Asanovi\'{c}, Krste},
  title     = {Chisel: constructing hardware in a Scala embedded language},
  year      = {2012},
  isbn      = {9781450311991},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2228360.2228584},
  doi       = {10.1145/2228360.2228584},
  abstract  = {In this paper we introduce Chisel, a new hardware construction language that supports advanced hardware design using highly parameterized generators and layered domain-specific hardware languages. By embedding Chisel in the Scala programming language, we raise the level of hardware design abstraction by providing concepts including object orientation, functional programming, parameterized types, and type inference. Chisel can generate a high-speed C++-based cycle-accurate software simulator, or low-level Verilog designed to map to either FPGAs or to a standard ASIC flow for synthesis. This paper presents Chisel, its embedding in Scala, hardware examples, and results for C++ simulation, Verilog emulation and ASIC synthesis.},
  booktitle = {Proceedings of the 49th Annual Design Automation Conference},
  pages     = {1216–1225},
  numpages  = {10},
  keywords  = {CAD},
  location  = {San Francisco, California},
  series    = {DAC '12}
}

@techreport{asanovic2014riscv,
  author      = {Asanovi{'c}, Krste and Patterson, David A.},
  title       = {Instruction sets should be free: The case for RISC-V},
  institution = {EECS Department, University of California, Berkeley},
  year        = {2014},
  number      = {UCB/EECS-2014-146},
  url         = {http://www.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-146.html}
}

misc{genc2019gemmini,
  author        = {Genc, Hasan and Haj-Ali, Ameer and Iyer, Vighnesh and Mao, Howard and Schmidt, Colin and Amid, Alon and Zhao, Jerry and Grubb, Daniel and Liew, Harrison and Ou, Albert and Steffl, Samuel and Wright, John and Stoica, Ion and Ragan-Kelley, Jonathan and Asanovi{'c}, Krste and Nikoli{'c}, Borivoje and Shao, Yakun Sophia},
  title         = {Gemmini: An agile systolic array generator enabling systematic evaluations of deep-learning architectures},
  year          = {2019},
  eprint        = {1911.09925},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AR}
}

@inproceedings{karandikar2018firesim,
  author    = {Karandikar, Sagar and Mao, Howard and Kim, Donggyu and Biancolin, David and Amid, Alon and Lee, Dayeol and Han, Nathan and Gope, Dima and Schmidt, Colin and Eckert, Chris and Ou, Albert and Pemberton, Nathan and Wright, John and Cook, Henry and Asanovi{'c}, Krste and Nikoli{'c}, Borivoje and Bachrach, Jonathan},
  title     = {{FireSim: FPGA-Accelerated Cycle-Exact Scale-Out System Simulation in the Public Cloud}},
  booktitle = {Proceedings of the 45th Annual International Symposium on Computer Architecture (ISCA)},
  pages     = {29-42},
  year      = {2018},
  doi       = {10.1109/ISCA.2018.00013}
}

@techreport{waterman2015riscvpriv,
  author      = {Waterman, Andrew and Lee, Yunsup and Patterson, David A. and Asanovi{'c}, Krste},
  title       = {The RISC-V instruction set manual volume II: Privileged architecture version 1.7},
  institution = {EECS Department, University of California, Berkeley},
  year        = {2015},
  number      = {UCB/EECS-2015-49},
  url         = {https://www2.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-49.html}
}

@article{kung1982systolic,
  author   = {Kung},
  journal  = {Computer},
  title    = {Why systolic architectures?},
  year     = {1982},
  volume   = {15},
  number   = {1},
  pages    = {37-46},
  keywords = {Costs;Hardware;Assembly systems;Computer architecture;Data flow computing;Concurrent computing;Application software;Signal processing;Image processing;Computer interfaces},
  doi      = {10.1109/MC.1982.1653825}
}

@software{opensbi_project,
  author       = {{RISC-V International OpenSBI Project Contributors}},
  title        = {{OpenSBI: RISC-V Open Source Supervisor Binary Interface}},
  howpublished = {GitHub repository},
  url          = {https://github.com/riscv-software-src/opensbi},
  year         = {2023},
  note         = {Accessed: November 28, 2023}
}

@misc{tarassov_vivado-risc-v_nodate,
  title  = {vivado-risc-v: FPGA based RISC-V Systems & Workloads including Linux & Debian on an SD Card for Xilinx FPGAs with Vivado and Vitis},
  url    = {https://github.com/eugene-tarassov/vivado-risc-v},
  author = {Tarassov, Eugene},
  note   = {Accessed: November 28, 2023}
}

@Article{gookyi2023gemmini_case_study,
AUTHOR = {Gookyi, Dennis Agyemanh Nana and Lee, Eunchong and Kim, Kyungho and Jang, Sung-Joon and Lee, Sang-Seol},
TITLE = {Deep Learning Accelerators’ Configuration Space Exploration Effect on Performance and Resource Utilization: A Gemmini Case Study},
JOURNAL = {Sensors},
VOLUME = {23},
YEAR = {2023},
NUMBER = {5},
ARTICLE-NUMBER = {2380},
URL = {https://www.mdpi.com/1424-8220/23/5/2380},
PubMedID = {36904584},
ISSN = {1424-8220},
ABSTRACT = {Though custom deep learning (DL) hardware accelerators are attractive for making inferences in edge computing devices, their design and implementation remain a challenge. Open-source frameworks exist for exploring DL hardware accelerators. Gemmini is an open-source systolic array generator for agile DL accelerator exploration. This paper details the hardware/software components generated using Gemmini. The general matrix-to-matrix multiplication (GEMM) of different dataflow options, including output/weight stationary (OS/WS), was explored in Gemmini to estimate the performance relative to a CPU implementation. The Gemmini hardware was implemented on an FPGA device to explore the effect of several accelerator parameters, including array size, memory capacity, and the CPU/hardware image-to-column (im2col) module, on metrics such as the area, frequency, and power. This work revealed that regarding the performance, the WS dataflow offered a speedup of 3× relative to the OS dataflow, and the hardware im2col operation offered a speedup of 1.1× relative to the operation on the CPU. For hardware resources, an increase in the array size by a factor of 2 led to an increase in both the area and power by a factor of 3.3, and the im2col module led to an increase in area and power by factors of 1.01 and 1.06, respectively.},
DOI = {10.3390/s23052380}
}

@manual{sifive2018tilelink,
  author  = {{SiFive Inc.}},
  title   = {{SiFive TileLink Specification}},
  year    = {2018},
  month   = {dec},
  day     = {3},
  version = {1.7.1},
  url     = {https://sifive.cdn.prismic.io/sifive%2F57f93ecf-2c42-46f7-9818-bcdd7d39400a_tilelink-spec-1.7.1.pdf},
  note    = {Accessed: Jun. 6, 2025}
}

@inproceedings{10.1145/3079856.3080246,
author = {Jouppi, Norman P. and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and Boyle, Rick and Cantin, Pierre-luc and Chao, Clifford and Clark, Chris and Coriell, Jeremy and Daley, Mike and Dau, Matt and Dean, Jeffrey and Gelb, Ben and Ghaemmaghami, Tara Vazir and Gottipati, Rajendra and Gulland, William and Hagmann, Robert and Ho, C. Richard and Hogberg, Doug and Hu, John and Hundt, Robert and Hurt, Dan and Ibarz, Julian and Jaffey, Aaron and Jaworski, Alek and Kaplan, Alexander and Khaitan, Harshit and Killebrew, Daniel and Koch, Andy and Kumar, Naveen and Lacy, Steve and Laudon, James and Law, James and Le, Diemthu and Leary, Chris and Liu, Zhuyuan and Lucke, Kyle and Lundin, Alan and MacKean, Gordon and Maggiore, Adriana and Mahony, Maire and Miller, Kieran and Nagarajan, Rahul and Narayanaswami, Ravi and Ni, Ray and Nix, Kathy and Norrie, Thomas and Omernick, Mark and Penukonda, Narayana and Phelps, Andy and Ross, Jonathan and Ross, Matt and Salek, Amir and Samadiani, Emad and Severn, Chris and Sizikov, Gregory and Snelham, Matthew and Souter, Jed and Steinberg, Dan and Swing, Andy and Tan, Mercedes and Thorson, Gregory and Tian, Bo and Toma, Horia and Tuttle, Erick and Vasudevan, Vijay and Walter, Richard and Wang, Walter and Wilcox, Eric and Yoon, Doe Hyun},
title = {In-Datacenter Performance Analysis of a Tensor Processing Unit},
year = {2017},
isbn = {9781450348928},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3079856.3080246},
doi = {10.1145/3079856.3080246},
abstract = {Many architects believe that major improvements in cost-energy-performance must now come from domain-specific hardware. This paper evaluates a custom ASIC---called a Tensor Processing Unit (TPU) --- deployed in datacenters since 2015 that accelerates the inference phase of neural networks (NN). The heart of the TPU is a 65,536 8-bit MAC matrix multiply unit that offers a peak throughput of 92 TeraOps/second (TOPS) and a large (28 MiB) software-managed on-chip memory. The TPU's deterministic execution model is a better match to the 99th-percentile response-time requirement of our NN applications than are the time-varying optimizations of CPUs and GPUs that help average throughput more than guaranteed latency. The lack of such features helps explain why, despite having myriad MACs and a big memory, the TPU is relatively small and low power. We compare the TPU to a server-class Intel Haswell CPU and an Nvidia K80 GPU, which are contemporaries deployed in the same datacenters. Our workload, written in the high-level TensorFlow framework, uses production NN applications (MLPs, CNNs, and LSTMs) that represent 95\% of our datacenters' NN inference demand. Despite low utilization for some applications, the TPU is on average about 15X -- 30X faster than its contemporary GPU or CPU, with TOPS/Watt about 30X -- 80X higher. Moreover, using the CPU's GDDR5 memory in the TPU would triple achieved TOPS and raise TOPS/Watt to nearly 70X the GPU and 200X the CPU.},
booktitle = {Proceedings of the 44th Annual International Symposium on Computer Architecture},
pages = {1–12},
numpages = {12},
keywords = {CNN, DNN, GPU, LSTM, MLP, RNN, TPU, TensorFlow, accelerator, deep learning, domain-specific architecture, neural network},
location = {Toronto, ON, Canada},
series = {ISCA '17}
}

@article{jouppi2017tpu,
author = {Jouppi, Norman P. and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and Boyle, Rick and Cantin, Pierre-luc and Chao, Clifford and Clark, Chris and Coriell, Jeremy and Daley, Mike and Dau, Matt and Dean, Jeffrey and Gelb, Ben and Ghaemmaghami, Tara Vazir and Gottipati, Rajendra and Gulland, William and Hagmann, Robert and Ho, C. Richard and Hogberg, Doug and Hu, John and Hundt, Robert and Hurt, Dan and Ibarz, Julian and Jaffey, Aaron and Jaworski, Alek and Kaplan, Alexander and Khaitan, Harshit and Killebrew, Daniel and Koch, Andy and Kumar, Naveen and Lacy, Steve and Laudon, James and Law, James and Le, Diemthu and Leary, Chris and Liu, Zhuyuan and Lucke, Kyle and Lundin, Alan and MacKean, Gordon and Maggiore, Adriana and Mahony, Maire and Miller, Kieran and Nagarajan, Rahul and Narayanaswami, Ravi and Ni, Ray and Nix, Kathy and Norrie, Thomas and Omernick, Mark and Penukonda, Narayana and Phelps, Andy and Ross, Jonathan and Ross, Matt and Salek, Amir and Samadiani, Emad and Severn, Chris and Sizikov, Gregory and Snelham, Matthew and Souter, Jed and Steinberg, Dan and Swing, Andy and Tan, Mercedes and Thorson, Gregory and Tian, Bo and Toma, Horia and Tuttle, Erick and Vasudevan, Vijay and Walter, Richard and Wang, Walter and Wilcox, Eric and Yoon, Doe Hyun},
title = {In-Datacenter Performance Analysis of a Tensor Processing Unit},
year = {2017},
issue_date = {May 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/3140659.3080246},
doi = {10.1145/3140659.3080246},
abstract = {Many architects believe that major improvements in cost-energy-performance must now come from domain-specific hardware. This paper evaluates a custom ASIC---called a Tensor Processing Unit (TPU) --- deployed in datacenters since 2015 that accelerates the inference phase of neural networks (NN). The heart of the TPU is a 65,536 8-bit MAC matrix multiply unit that offers a peak throughput of 92 TeraOps/second (TOPS) and a large (28 MiB) software-managed on-chip memory. The TPU's deterministic execution model is a better match to the 99th-percentile response-time requirement of our NN applications than are the time-varying optimizations of CPUs and GPUs that help average throughput more than guaranteed latency. The lack of such features helps explain why, despite having myriad MACs and a big memory, the TPU is relatively small and low power. We compare the TPU to a server-class Intel Haswell CPU and an Nvidia K80 GPU, which are contemporaries deployed in the same datacenters. Our workload, written in the high-level TensorFlow framework, uses production NN applications (MLPs, CNNs, and LSTMs) that represent 95\% of our datacenters' NN inference demand. Despite low utilization for some applications, the TPU is on average about 15X -- 30X faster than its contemporary GPU or CPU, with TOPS/Watt about 30X -- 80X higher. Moreover, using the CPU's GDDR5 memory in the TPU would triple achieved TOPS and raise TOPS/Watt to nearly 70X the GPU and 200X the CPU.},
journal = {SIGARCH Comput. Archit. News},
month = jun,
pages = {1–12},
numpages = {12},
keywords = {CNN, DNN, GPU, LSTM, MLP, RNN, TPU, TensorFlow, accelerator, deep learning, domain-specific architecture, neural network}
}

@misc{nvidia2018xavier,
  author       = {NVIDIA},
  title        = {NVIDIA Xavier},
  howpublished = {Hot Chips 30},
  year         = {2018},
  url          = {https://old.hotchips.org/hc30/1conf/1.12_Nvidia_XavierHotchips2018Final_814.pdf},
  note         = {Accessed: Jun. 9, 2025}
}

@INPROCEEDINGS{farshchi2019nvdla,
  author={Farshchi, Farzad and Huang, Qijing and Yun, Heechul},
  booktitle={2019 2nd Workshop on Energy Efficient Machine Learning and Cognitive Computing for Embedded Applications (EMC2)}, 
  title={Integrating NVIDIA Deep Learning Accelerator (NVDLA) with RISC-V SoC on FireSim}, 
  year={2019},
  volume={},
  number={},
  pages={21-25},
  keywords={Field programmable gate arrays;Open source software;Random access memory;Rockets;Clocks;Protocols;Hardware;NVDLA;FireSim;RISC-V;FPGA;Cloud;DNN;Embedded Systems},
  doi={10.1109/EMC249363.2019.00012}}

@book{sze2020efficient, title={Efficient processing of deep neural networks}, url={https://doi.org/10.1007/978-3-031-01766-7}, DOI={10.1007/978-3-031-01766-7}, journal={Synthesis lectures on computer architecture}, author={Sze, Vivienne and Chen, Yu-Hsin and Yang, Tien-Ju and Emer, Joel S.}, year={2020}, month=jan }

@INPROCEEDINGS{horowitz2014energy,
  author={Horowitz, Mark},
  booktitle={2014 IEEE International Solid-State Circuits Conference Digest of Technical Papers (ISSCC)}, 
  title={1.1 Computing's energy problem (and what we can do about it)}, 
  year={2014},
  volume={},
  number={},
  pages={10-14},
  keywords={CMOS integrated circuits;Hardware;Transistors;Voltage control;CMOS technology;Energy efficiency;Logic gates},
  doi={10.1109/ISSCC.2014.6757323}}



% Full-day Tutorial on FireSim and Chipyard at ISCA 2023
% Speakers: Sagar Karandikar, Jerry Zhao, Vighnesh Iyer, JunSun Choi, Joonho Whangbo, Dima Nikiforov, Shengjun Kris Dong. Full-day Tutorial on FireSim and Chipyard at ISCA 2023. Orlando, FL, June 2023.
% Slides: https://fires.im/isca-2023-tutorial/

% https://fires.im/isca23-slides-pdf/02_chipyard_basics.pdf

@misc{zhao2021chipyard,
  author       = {Zhao, J.},
  title        = {Chipyard Intro and Fundamentals},
  howpublished = {Presentation Slides, ISCA 2021 Tutorial},
  year         = {2021},
  url          = {https://fires.im/isca21-slides-pdf/02_chipyard_basics.pdf},
  note         = {Accessed: Jun. 6, 2025}
}

@article{wulf1995hitting,
author = {Wulf, Wm. A. and McKee, Sally A.},
title = {Hitting the memory wall: implications of the obvious},
year = {1995},
issue_date = {March 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {1},
issn = {0163-5964},
url = {https://doi.org/10.1145/216585.216588},
doi = {10.1145/216585.216588},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {20–24},
numpages = {5}
}

@article{mittal2021survey,
title = {A survey On hardware accelerators and optimization techniques for RNNs},
journal = {Journal of Systems Architecture},
volume = {112},
pages = {101839},
year = {2021},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2020.101839},
url = {https://www.sciencedirect.com/science/article/pii/S1383762120301314},
author = {Sparsh Mittal and Sumanth Umesh},
keywords = {Recurrent neural networks, Deep learning, GPU, FPGA, ASIC, Pruning, Parallelization, Low-precision},
abstract = {“Recurrent neural networks” (RNNs) are powerful artificial intelligence models that have shown remarkable effectiveness in several tasks such as music generation, speech recognition and machine translation. RNN computations involve both intra-timestep and inter-timestep dependencies. Due to these features, hardware acceleration of RNNs is more challenging than that of CNNs. Recently, several researchers have proposed hardware architectures for RNNs. In this paper, we present a survey of GPU/FPGA/ASIC-based accelerators and optimization techniques for RNNs. We highlight the key ideas of different techniques to bring out their similarities and differences. Improvements in deep-learning algorithms have inevitably gone hand-in-hand with the improvements in the hardware-accelerators. Nevertheless, there is a need and scope of even greater synergy between these two fields. This survey seeks to synergize the efforts of researchers in the area of deep learning, computer architecture, and chip-design.}
}


% Below are references from another document

@online{asml2022moore,
  author = {{ASML}},
  title  = {Moore's Law: What's next in the evolution of chipmaking},
  year   = {2022},
  url    = {https://www.asml.com/en/news/stories/2022/moores-law-evolution},
  note   = {Accessed: Dec. 30, 2024}
}

@techreport{waterman2014riscv,
  author      = {Andrew Waterman and Yunsup Lee and David A. Patterson and Krste Asanovic},
  title       = {The {RISC-V} instruction set manual, volume {I}: User-level {ISA}, version 2.0},
  institution = {EECS Department, University of California, Berkeley},
  year        = {2014},
  number      = {UCB/EECS-2014-54},
  month       = {may},
  type        = {Tech. Rep.}
}

@online{github2023octoverse,
  author = {{GitHub}},
  title  = {Octoverse: The state of open source and AI},
  year   = {2023},
  url    = {https://github.blog/news-insights/research/the-state-of-open-source-and-ai/},
  note   = {Accessed: Dec. 30, 2024}
}

@online{krewell2022riscvsummit,
  author       = {Kevin Krewell},
  title        = {{RISC-V} Summit 2022: All Your {CPUs} Belong to Us},
  organization = {EETimes},
  year         = {2022},
  url          = {https://www.eetimes.com/risc-v-summit-2022-all-your-cpus-belong-to-us/},
  note         = {Accessed: Dec. 30, 2024}
}

@inproceedings{holler2019opensource,
  author    = {Höller, R. and Haselberger, D. and Ballek, D. and Rössler, P. and Krapfenbauer, M. and Linauer, M.},
  title     = {Open-Source {RISC-V} Processor {IP} Cores for {FPGAs} - Overview and Evaluation},
  booktitle = {2019 8th Mediterranean Conference on Embedded Computing (MECO)},
  year      = {2019},
  pages     = {1--6}
}

@online{sifive2024portfolio,
  author = {{SiFive}},
  title  = {A Winning Processor Portfolio},
  year   = {2024},
  url    = {https://www.sifive.com/risc-v-core-ip},
  note   = {Accessed: Dec. 30, 2024}
}

@online{riscv2024members,
  author = {{RISC-V International}},
  title  = {Members},
  year   = {2024},
  url    = {https://riscv.org/members/},
  note   = {Accessed: Dec. 30, 2024}
}

@article{wu2021intelligent,
  author  = {Wu, W. and Su, D. and Yuan, B. and Li, Y.},
  title   = {Intelligent Security Monitoring System Based on {RISC-V} {SoC}},
  journal = {Electronics},
  year    = {2021},
  volume  = {10},
  number  = {11},
  pages   = {1366},
  doi     = {10.3390/electronics10111366}
}

@article{lee2020miot,
  author  = {Lee, D. and Moon, H. and Oh, S. and Park, D.},
  title   = {{mIoT}: Metamorphic {IoT} Platform for On-Demand Hardware Replacement in Large-Scaled {IoT} Applications},
  journal = {Sensors},
  year    = {2020},
  volume  = {20},
  number  = {12},
  pages   = {3337},
  doi     = {10.3390/s20123337}
}

@article{zhang2021heterogeneous,
  author  = {Zhang, H. and Wu, X. and Du, Y. and Guo, H. and Li, C. and Yuan, Y. and Zhang, M. and Zhang, S.},
  title   = {A Heterogeneous {RISC-V} Processor for Efficient {DNN} Application in Smart Sensing System},
  journal = {Sensors},
  year    = {2021},
  volume  = {21},
  number  = {19},
  pages   = {6491},
  doi     = {10.3390/s21196491}
}

@article{kieudonguyen2024hardware,
  author  = {Kieu-do-Nguyen, B. and Nguyen, K. and Nguyen, T. B. and Ma, K. and Ta, T. T. and Le, Duc-Hung D. and Pham, Cong-Kha C. and Hoang, T. H.},
  title   = {Hardware Software Co-Design for Multi-Threaded Computation on {RISC-V}-Based Multicore System},
  journal = {IEEE Access},
  year    = {2024},
  volume  = {12},
  pages   = {177312--177326},
  doi     = {10.1109/ACCESS.2024.3361308}
}

@online{intel2025hybrid,
  author = {{Intel}},
  title  = {How hybrid design works},
  year   = {2025},
  url    = {https://www.intel.com/content/www/us/en/gaming/resources/how-hybrid-design-works.html},
  note   = {Accessed: Jan. 1, 2025}
}

@article{bensalem2023efficient,
  author  = {Bensalem, H. and Blaqui{\`e}re, Y. and Savaria, Y.},
  title   = {An efficient {OpenCL}-based implementation of a {SHA-3} co-processor on an {FPGA}-centric platform},
  journal = {IEEE Transactions on Circuits and Systems II: Express Briefs},
  year    = {2023},
  volume  = {70},
  number  = {3},
  pages   = {1144--1148},
  doi     = {10.1109/TCSII.2022.3210340}
}

@techreport{waterman2015riscvprivileged,
  author      = {Waterman, A. and Lee, Y. and Avizienis, R. and Patterson, D. A. and Asanovic, K.},
  title       = {The {RISC-V} instruction set manual volume {II}: Privileged architecture version 1.7},
  institution = {EECS Department, University of California, Berkeley},
  year        = {2015},
  number      = {UCB/EECS-2015-49},
  type        = {Tech. Rep.}
}

@software{paponVexRiscv,
  author    = {Papon, Charles},
  title     = {SpinalHDL/VexRiscv},
  publisher = {GitHub},
  url       = {https://github.com/SpinalHDL/VexRiscv},
  year      = {2024},
  note      = {Accessed: Dec. 30, 2024}
}

@software{paponVexiiRiscv,
  author    = {Papon, Charles},
  title     = {SpinalHDL/VexiiRiscv},
  publisher = {GitHub},
  url       = {https://github.com/SpinalHDL/VexiiRiscv},
  year      = {2024},
  note      = {Accessed: Dec. 24, 2024}
}

@techreport{asanovic2016rocket,
  author      = {Asanovic, K. and Avizienis, R. and Bachrach, J. and Beamer, S. and Biancolin, D. and Celio, C. and Cook, H. and Dabbelt, D. and Hauser, J. and Izraelevitz, A. and others},
  title       = {The Rocket Chip Generator},
  institution = {EECS Department, University of California, Berkeley},
  year        = {2016},
  number      = {UCB/EECS-2016-17},
  type        = {Tech. Rep.}
}

@techreport{celio2015boom,
  author      = {Celio, C. and Patterson, D. A. and Asanovic, K.},
  title       = {The {Berkeley} out-of-order machine ({BOOM}): An industry-competitive, synthesizable, parameterized {RISC-V} processor},
  institution = {EECS Department, University of California, Berkeley},
  year        = {2015},
  number      = {UCB/EECS-2015-167},
  type        = {Tech. Rep.}
}

@manual{celio2016boom_spec,
  author       = {Celio, C. and Patterson, D. and Asanovic, K.},
  title        = {The {Berkeley} Out-of-Order Machine ({BOOM}) Design Specification},
  organization = {University of California, Berkeley},
  year         = {2016}
}

@inproceedings{zhao2020sonicboom,
  author    = {Zhao, J. and Korpan, B. and Gonzalez, A. and Asanovic, K.},
  title     = {Sonicboom: The 3rd generation {Berkeley} out-of-order machine},
  booktitle = {Fourth Workshop on Computer Architecture Research with {RISC-V} (CARRV)},
  year      = {2020},
  month     = {may},
  pages     = {1--7}
}

@inproceedings{kermarrec2019litex,
  author    = {Kermarrec, F. and Bourdeauducq, S. and Le Lann, J.-C. and Badier, H.},
  title     = {{LiteX}: An open-source {SoC} builder and library based on {Migen} {Python} {DSL}},
  booktitle = {Proceedings of the Workshop on Open Source Design Automation (OSDA)},
  year      = {2019},
  address   = {Florence, Italy},
  month     = {mar},
  note      = {Colocated with DATE 2019 Design Automation and Test in Europe}
}

Below are Gemmini-generated

@misc{Genc2022GemminiMLSys,
  author       = {Genc, Hasan and Guo, Simon and Kim, Seah and Nikiforov, Vadim (Dima)},
  title        = {{Gemmini @ MLSys 2022}},
  howpublished = {Presentation Slides, MLSys 2022 Tutorial},
  year         = {2022},
  url          = {https://mlsys.org/virtual/2022/tutorial/18433},
  note         = {Accessed: [Your Access Date]}
}

@misc{Genc2021GemminiIISWC,
  author       = {Genc, Hasan and Nikiforov, Vadim (Dima) and Guo, Simon and Nandakumar, Avinash},
  title        = {{Gemmini @ IISWC 2021}},
  howpublished = {Presentation Slides, IISWC 2021 Tutorial},
  year         = {2021},
  note         = {Accessed: [Your Access Date]}
}


% Belows are crypto-related references

@article{elhajj2023analysis,
  author  = {El-hajj, M. and Mousawi, H. and Fadlallah, A.},
  title   = {Analysis of Lightweight Cryptographic Algorithms on {IoT} Hardware Platform},
  journal = {Future Internet},
  year    = {2023},
  volume  = {15},
  number  = {2},
  pages   = {54},
  doi     = {10.3390/fi15020054}
}

@inproceedings{abbas2014implementation,
  author    = {Abbas, Y. A. and Jidin, R. and Jamil, N. and Z'aba, M. R. and Rusli, M. E. and Tariq, B.},
  title     = {Implementation of {PRINCE} algorithm in {FPGA}},
  booktitle = {Proceedings of the 6th International Conference on Information Technology and Multimedia},
  year      = {2014},
  address   = {Putrajaya, Malaysia},
  month     = {Nov}
}

@article{abdullah2021efficient,
  author  = {Abdullah, A. A. and Obeid, N. R.},
  title   = {Efficient Implementation for {PRINCE} Algorithm in {FPGA} Based on the {BB84} Protocol},
  journal = {Journal of Physics: Conference Series},
  year    = {2021},
  volume  = {1818},
  number  = {1},
  pages   = {012216},
  doi     = {10.1088/1742-6596/1818/1/012216}
}

@incollection{guo2008energy,
  author    = {Guo, X. and Chen, Z. and Schaumont, P.},
  title     = {Energy and performance evaluation of an {FPGA}-based {SoC} platform with {AES} and {PRESENT} coprocessors},
  booktitle = {Embedded Computer Systems: Architectures, Modeling, and Simulation},
  editor    = {Rerekovi{\'c}, M. and Dimopoulos, N. and Wong, S.},
  publisher = {Springer},
  address   = {Berlin, Heidelberg},
  year      = {2008},
  pages     = {106--115},
  series    = {Lecture Notes in Computer Science},
  volume    = {5114},
  doi       = {10.1007/978-3-540-69832-5_11}
}

@inproceedings{sundal2017efficient,
  author    = {Sundal, M. and Chaves, R.},
  title     = {Efficient {FPGA} implementation of the {SHA-3} hash function},
  booktitle = {2017 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)},
  year      = {2017},
  pages     = {86--91},
  doi       = {10.1109/ISVLSI.2017.23}
}

@article{ma2023design,
  author  = {Ma, K.-M. and Le, D.-H. and Pham, C.-K. and Hoang, T.-T.},
  title   = {Design of an {SoC} Based on 32-Bit {RISC-V} Processor with Low-Latency Lightweight Cryptographic Cores in {FPGA}},
  journal = {Future Internet},
  year    = {2023},
  volume  = {15},
  number  = {5},
  pages   = {186},
  doi     = {10.3390/fi15050186}
}

@inproceedings{borghoff2012prince,
  author    = {Borghoff, J. and Canteaut, A. and G{\"u}neysu, T. and Kavun, E. B. and Knezevic, M. and Knudsen, L. R. and Leander, G. and Nikov, V. and Paar, C. and Rechberger, C. and others},
  title     = {{PRINCE} - A Low-latency Block Cipher for Pervasive Computing Applications},
  booktitle = {Advances in Cryptology - ASIACRYPT 2012: 18th International Conference on the Theory and Application of Cryptology and Information Security},
  editor    = {Wang, X. and Sako, K.},
  publisher = {Springer},
  address   = {Berlin, Heidelberg},
  year      = {2012},
  pages     = {208--225},
  series    = {Lecture Notes in Computer Science},
  volume    = {7658},
  doi       = {10.1007/978-3-642-34961-4_14}
}

@inproceedings{bernstein2008chacha,
  author    = {Bernstein, D. J.},
  title     = {{ChaCha}, a variant of {Salsa20}},
  booktitle = {Workshop Record of SASC '08: The State of the Art of Stream Ciphers},
  year      = {2008},
  address   = {Lausanne, Switzerland},
  month     = {Feb},
  pages     = {3--5}
}

@incollection{bernstein2008salsa20family,
  author    = {Bernstein, D. J.},
  title     = {The {Salsa20} family of stream ciphers},
  booktitle = {New Stream Cipher Designs: The eSTREAM Finalists},
  editor    = {Robshaw, M. and Billet, O.},
  publisher = {Springer},
  address   = {Berlin, Heidelberg},
  year      = {2008},
  pages     = {84--97},
  series    = {Lecture Notes in Computer Science},
  volume    = {4986},
  doi       = {10.1007/978-3-540-68351-3_8}
}

@misc{bernsteinSalsa20spec,
  author       = {Bernstein, D. J.},
  title        = {{Salsa20} specification},
  howpublished = {eSTREAM Project Algorithm Description},
  year         = {2005},
  url          = {http://www.ecrypt.eu.org/stream/salsa20pf.html},
  note         = {Accessed: Dec. 25, 2024}
}

@techreport{rfc8439,
  author      = {Nir, Y. and Langley, A.},
  title       = {{RFC} 8439: {ChaCha20} and {Poly1305} for {IETF} Protocols},
  institution = {RFC Editor},
  year        = {2018},
  month       = {June},
  type        = {RFC},
  number      = {8439},
  doi         = {10.17487/RFC8439}
}

@techreport{nistFIPS202,
  author      = {{National Institute of Standards and Technology}},
  title       = {{SHA-3} standard: Permutation-based hash and extendable-output functions},
  institution = {NIST},
  year        = {2015},
  month       = {Aug},
  type        = {FIPS PUB},
  number      = {202},
  url         = {https://doi.org/10.6028/NIST.FIPS.202},
  note        = {Accessed on 24 December 2024}
}

@inproceedings{bogdanov2007present,
  author    = {Bogdanov, A. and Knudsen, L. R. and Leander, G. and Paar, C. and Poschmann, A. and Robshaw, M. J. B. and Seurin, Y. and Vikkelsoe, C.},
  title     = {{PRESENT}: An ultra-lightweight block cipher},
  booktitle = {Cryptographic Hardware and Embedded Systems - CHES 2007: 9th International Workshop},
  editor    = {Paar, C. and Pelzl, J.},
  publisher = {Springer},
  address   = {Berlin, Heidelberg},
  year      = {2007},
  pages     = {450--466},
  series    = {Lecture Notes in Computer Science},
  volume    = {4727},
  doi       = {10.1007/978-3-540-74735-2_31}
}

@inproceedings{guo2008energy_samos,
  author    = {Guo, X. and Chen, Z. and Schaumont, P.},
  title     = {Energy and performance evaluation of an {FPGA}-based {SoC} platform with {AES} and {PRESENT} coprocessors},
  booktitle = {Embedded Computer Systems: Architectures, Modeling, and Simulation: 8th International Workshop, SAMOS 2008},
  editor    = {Pnevmatikatos, D. and Sima, M. and Kaxiras, S.},
  publisher = {Springer},
  address   = {Berlin, Heidelberg},
  year      = {2008},
  month     = {Jul},
  pages     = {106--115},
  series    = {Lecture Notes in Computer Science},
  volume    = {5114},
  doi       = {10.1007/978-3-540-69832-5_11}
}

@inproceedings{tehrani2020riscv,
  author    = {Tehrani, E. and Graba, T. and Merabet, A. S. and Danger, J.-L.},
  title     = {{RISC-V} extension for lightweight cryptography},
  booktitle = {2020 23rd Euromicro Conference on Digital System Design (DSD)},
  year      = {2020},
  pages     = {222--228},
  doi       = {10.1109/DSD51259.2020.00046}
}

@inproceedings{stoffelen2019efficient,
  author    = {Stoffelen, K.},
  title     = {Efficient cryptography on the {RISC-V} architecture},
  booktitle = {Progress in Cryptology – LATINCRYPT 2019: 6th International Conference on Cryptology and Information Security in Latin America},
  editor    = {Barreto, P. S. L. M. and R{\`a}fols, C.},
  publisher = {Springer},
  address   = {Cham},
  year      = {2019},
  pages     = {323--340},
  series    = {Lecture Notes in Computer Science},
  volume    = {11774},
  doi       = {10.1007/978-3-030-30530-7_17}
}




@software{enjoydigitalLitex,
  author    = {{EnjoyDigital}},
  title     = {{LiteX} Framework - Build your hardware, easily!},
  publisher = {GitHub},
  url       = {https://github.com/enjoy-digital/litex},
  year      = {2024},
  note      = {Accessed: Dec. 25, 2024}
}







@article{at2014compact,
  author  = {At, N. and Beuchat, J.-L. and Okamoto, E. and San, I. and Yamazaki, T.},
  title   = {Compact hardware implementations of {ChaCha}, {BLAKE}, {Threefish}, and {Skein} on {FPGA}},
  journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  year    = {2014},
  volume  = {61},
  number  = {2},
  pages   = {485--498},
  doi     = {10.1109/TCSI.2013.2280026}
}





